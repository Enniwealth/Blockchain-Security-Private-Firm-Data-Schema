[
  {
    "id": "gs_cantina_infinifi_001",
    "report_url": "https://cantina.xyz/portfolio/2a2026d0-0cea-4406-baac-0e1ee0ac1f66",
    "project_name": "infiniFi PR 224",
    "github_url": "https://github.com/InfiniFi-Labs/infinifi-contracts",
    "language": "solidity",
    "chain": "ethereum",
    "contest_date": "2025-11-25",
    "vulnerability_type": "accounting_bypass",
    "severity": "high",
    "difficulty_tier": 3,
    "context": "cross_contract",
    "is_vulnerable": true,
    "title": "Losses Within Liquid Buffer Do Not Burn Shares, Overstating Supply",
    "description": "The OutlandVault.portalUpdate function fails to burn shares when reported losses are less than or equal to current liquid assets. This causes the vault to maintain inflated share supply while backing assets are reduced, breaking the assumption that share supply equals asset backing. Subsequent redemptions can hit InsufficientLiquidity errors because outstanding shares exceed actual backing.",
    "primary_file": {
      "name": "OutlandVault.sol",
      "path": "src/OutlandVault.sol",
      "lines": "150-180",
      "content": "function portalUpdate(uint256 _totalAssetsValue) external onlyRole(PORTAL_ROLE) {\n    VaultSnapshot.Data memory snapshot = getVaultSnapshot();\n    uint256 sharesTotalBefore = snapshot.shareBalance;\n    \n    // Calculate new total shares based on remote asset value + local liquidity\n    uint256 sharesTotalAfter = toShares(_totalAssetsValue) + liquidShares();\n    \n    if (sharesTotalAfter < sharesTotalBefore) {\n        // Loss detected: old shares > new shares\n        uint256 sharesLost = sharesTotalBefore - sharesTotalAfter;\n        uint256 sharesLiquid = liquidShares();\n        \n        // BUG: Only burns if loss exceeds liquid buffer\n        // If loss < liquid, no burn occurs\n        if (sharesLost > sharesLiquid) {\n            uint256 sharesToBurn = sharesLost - sharesLiquid;\n            _burn(outlandFarm, sharesToBurn);\n            emit SharesBurned(sharesToBurn);\n        }\n        // If sharesLost <= sharesLiquid, NO BURN OCCURS\n        // Share supply stays inflated while assets decreased\n    } else {\n        // Gain: mint additional shares\n        uint256 sharesToMint = sharesTotalAfter - sharesTotalBefore;\n        _mint(outlandFarm, sharesToMint);\n        emit SharesMinted(sharesToMint);\n    }\n}"
    },
    "context_files": [
      {
        "name": "OutlandVault.sol (continued)",
        "path": "src/OutlandVault.sol",
        "relevance": "Shows the accounting functions that depend on correct share supply",
        "content": "function totalAssets() public view override returns (uint256) {\n    // Total assets = remote assets + local liquidity\n    uint256 remoteAssets = cachedRemoteAssets;\n    uint256 liquidAssets = balanceOf(address(this));\n    return remoteAssets + liquidAssets;\n}\n\nfunction liquidShares() public view returns (uint256) {\n    // Shares worth of current liquid assets\n    uint256 liquid = balanceOf(address(this));\n    return toShares(liquid);\n}\n\nfunction toShares(uint256 assets) public view returns (uint256) {\n    uint256 supply = totalSupply();\n    if (supply == 0) return assets;\n    return (assets * supply) / totalAssets();\n}"
      },
      {
        "name": "Example Loss Scenario",
        "path": "reference/accounting_example.md",
        "relevance": "Demonstrates how inflated shares lead to accounting errors",
        "content": "INITIAL STATE:\n- Farm holds: 200 shares\n- Vault has: 100 shares worth of liquid assets (USDC)\n- Remote assets value: 150 (from previous portalUpdate indicating 200 total)\n- Total reported assets: 250\n- Exchange rate: 1 share = 1.25 USDC\n\nLOSS EVENT:\n- Reported _totalAssetsValue drops to 150 (50 USDC loss occurred remotely)\n- sharesTotalBefore = 200\n- sharesTotalAfter = toShares(150) + liquidShares()\n                  = 120 + 80 = 200 (or slightly less)\n\nBUG TRIGGER:\n- sharesLost = 50\n- sharesLiquid = 100\n- Since sharesLost (50) < sharesLiquid (100), NO BURN\n- Farm keeps 200 shares\n\nACCOUNTING BREAK:\n- Farm has: 200 shares\n- But actual assets: 150 USDC total\n- Share exchange rate should be: 150 / 200 = 0.75 USDC per share\n- But code thinks: 200 shares backed by 200 shares worth = 1.0 USDC per share\n- Result: Share supply overstated by 50 shares worth\n- Later redemptions fail with InsufficientLiquidity"
      }
    ],
    "call_flow": [
      "1. OutlandVault holds 200 shares, vault has 100 liquid USDC + 150 remote",
      "2. Profit event → portalUpdate(200) increases reported assets",
      "3. Event occurs remotely: 50 USDC lost",
      "4. Remote portal reports portalUpdate(150) indicating new total assets",
      "5. OutlandVault.portalUpdate(150) executes",
      "6. Calculate: sharesTotalBefore = 200 (farm's share balance)",
      "7. Calculate: sharesTotalAfter = toShares(150) + liquidShares(100)",
      "8. Result: sharesTotalAfter ≈ 200 (slight reduction)",
      "9. sharesLost = 50",
      "10. sharesLiquid = 100 (liquid shares available)",
      "11. Check: if (50 > 100) → false, NO BURN",
      "12. Farm retains 200 shares despite 150 total assets",
      "13. Share supply inflated: 200 shares / 150 assets = overstated",
      "14. User tries to redeem 100 shares → needs 75 USDC but vault only has 100 liquid",
      "15. Redemption succeeds but creates InsufficientLiquidity for next user"
    ],
    "context_hint": "The vulnerability stems from the gate `if (sharesLost > sharesLiquid)` which prevents share burning when losses are covered by liquid reserves. The design philosophy appears to be: 'we have cash to cover the loss, so no need to adjust shares.' However, this breaks accounting invariant that shares represent claim on all assets (remote + local). Once liquid assets are deployed remotely again, those shares become backed by nothing, and the accounting is silently broken until the next portalUpdate that reports higher losses.",
    "expert_notes": "This is a subtle accounting error with high impact. The fix is straightforward: always burn the difference between sharesTotalBefore and sharesTotalAfter, regardless of liquidity. The audit team correctly identifies the root cause: the function must burn ALL losses, not just losses exceeding the buffer. The fix in PR #2a71b18 removes the liquidity gate and ensures share supply always reflects total asset backing. Critical insight: the '_totalAssetsValue' parameter MUST represent only remote assets (not including local liquid), so adding liquidShares() correctly represents total assets.",
    "fix_description": "Always burn the full delta between sharesTotalBefore and sharesTotalAfter when a loss is detected, without gating on liquidity.",
    "fix_code": "function portalUpdate(uint256 _totalAssetsValue) external onlyRole(PORTAL_ROLE) {\n    VaultSnapshot.Data memory snapshot = getVaultSnapshot();\n    uint256 sharesTotalBefore = snapshot.shareBalance;\n    \n    // Calculate new total shares: remote assets + local liquidity\n    uint256 sharesTotalAfter = toShares(_totalAssetsValue) + liquidShares();\n    \n    if (sharesTotalAfter < sharesTotalBefore) {\n        // Loss detected: always burn the full delta\n        uint256 sharesLost = sharesTotalBefore - sharesTotalAfter;\n        \n        // Burn shares lost, capped by farm balance to avoid over-burning\n        uint256 farmBalance = balanceOf(outlandFarm);\n        uint256 sharesToBurn = sharesLost <= farmBalance ? sharesLost : farmBalance;\n        \n        _burn(outlandFarm, sharesToBurn);\n        emit SharesBurned(sharesToBurn);\n    } else if (sharesTotalAfter > sharesTotalBefore) {\n        // Gain: mint additional shares\n        uint256 sharesToMint = sharesTotalAfter - sharesTotalBefore;\n        _mint(outlandFarm, sharesToMint);\n        emit SharesMinted(sharesToMint);\n    }\n}"
  },
  {
    "id": "gs_cantina_infinifi_002",
    "report_url": "https://cantina.xyz/portfolio/2a2026d0-0cea-4406-baac-0e1ee0ac1f66",
    "project_name": "infiniFi PR 224",
    "github_url": "https://github.com/InfiniFi-Labs/infinifi-contracts",
    "language": "solidity",
    "chain": "ethereum",
    "contest_date": "2025-11-25",
    "vulnerability_type": "missing_access_control",
    "severity": "medium",
    "difficulty_tier": 2,
    "context": "access_control",
    "is_vulnerable": true,
    "title": "Cross-Chain Pause Does Not Halt Portals, Enabling Fund Movement During Incidents",
    "description": "PortalHub and PortalOutpost inherit Pausable but all bridge entry points (sendTokens, receiveMessage, sendAssetsUpdate) lack the whenNotPaused guard. This allows keepers and connectors to continue pushing tokens and processing cross-chain messages even after the PAUSE role invokes pause(), nullifying the intended emergency brake during security incidents.",
    "primary_file": {
      "name": "PortalHub.sol",
      "path": "src/PortalHub.sol",
      "lines": "200-230",
      "content": "// VULNERABLE: Missing whenNotPaused modifiers\n\nfunction sendTokens(\n    uint256 _chainId,\n    address _token,\n    uint256 _amount,\n    address _receiver\n) external onlyRole(KEEPER_ROLE) {\n    // NO PAUSE CHECK - can send during emergency\n    require(assetMapping[_chainId].contains(_token), \"InvalidAsset\");\n    address connectorAsset = assetMapping[_chainId].get(_token);\n    \n    // Transfer and bridge\n    IERC20(_token).safeTransferFrom(msg.sender, address(this), _amount);\n    IConnector(connectors[_chainId]).sendTokens(_amount, connectorAsset, _receiver);\n    \n    emit TokensSent(_chainId, _token, _amount, _receiver);\n}\n\nfunction receiveMessage(\n    uint256 _senderChainId,\n    address _connector,\n    bytes calldata _data\n) external {\n    // NO PAUSE CHECK - can receive during emergency\n    require(isConnectorValid(_senderChainId, _connector), \"InvalidConnector\");\n    \n    (uint256 messageType, bytes memory payload) = OutlandMsgCodec.decode(_data);\n    if (messageType == OutlandMsgCodec.TRANSFER) {\n        // Process token transfers\n    }\n}"
    },
    "context_files": [
      {
        "name": "PortalOutpost.sol",
        "path": "src/PortalOutpost.sol",
        "relevance": "Similar missing pause guards on outbound bridges",
        "content": "// VULNERABLE: Missing whenNotPaused on bridge functions\n\nfunction sendTokens(\n    uint256 _chainId,\n    address _asset,\n    uint256 _amount\n) external onlyRole(KEEPER_ROLE) {\n    // NO PAUSE CHECK\n    IConnector connector = IConnector(connectors[_chainId]);\n    connector.sendTokens(_amount, asset, receiver);\n}\n\nfunction sendAssetsUpdate(\n    uint256 _destinationChain\n) external onlyRole(KEEPER_ROLE) {\n    // NO PAUSE CHECK\n    uint256 totalAssets = accounting.totalAssetsValue();\n    bytes memory data = OutlandMsgCodec.encodeAssetsUpdate(totalAssets);\n    \n    for (uint256 i = 0; i < connectors[_destinationChain].length; i++) {\n        connectors[_destinationChain][i].sendMessage(data);\n    }\n}\n\nfunction receiveMessage(\n    address _connector,\n    bytes calldata _data\n) external {\n    // NO PAUSE CHECK\n    // Process incoming messages\n}"
      },
      {
        "name": "CoreControlled.sol",
        "path": "src/CoreControlled.sol",
        "relevance": "Base contract providing Pausable functionality",
        "content": "import {Pausable} from \"openzeppelin-contracts/contracts/security/Pausable.sol\";\n\nabstract contract CoreControlled is Pausable {\n    // Inherited from Pausable\n    \n    function pause() external onlyRole(PAUSE_ROLE) {\n        _pause();\n    }\n    \n    function unpause() external onlyRole(DEFAULT_ADMIN_ROLE) {\n        _unpause();\n    }\n    \n    // But child contracts don't use whenNotPaused modifier\n}"
      }
    ],
    "call_flow": [
      "1. Admin detects security incident (e.g., connector compromise)",
      "2. Admin calls pause() via PAUSE_ROLE",
      "3. Pausable._pause() sets paused = true",
      "4. Goal: Stop all fund movement immediately",
      "5. But sendTokens() has NO whenNotPaused guard",
      "6. Keeper continues calling sendTokens() to bridge tokens",
      "7. Transaction executes successfully despite paused = true",
      "8. Tokens bridge out during emergency freeze",
      "9. receiveMessage() also lacks whenNotPaused",
      "10. Adversary connector sends messages that mint/withdraw funds",
      "11. Outpost continues processing despite pause()",
      "12. sendAssetsUpdate() bridges accounting updates without pause guard",
      "13. Fund movement continues uninterrupted during incident",
      "14. Pause becomes ineffective as emergency brake"
    ],
    "context_hint": "The Pausable mechanism is a standard OpenZeppelin emergency pattern, but it only works when all state-changing functions use the whenNotPaused modifier. Portal bridges are critical fund-movement paths that MUST respect the pause state. The absence of this guard means: (1) during a compromise of keeper credentials, attacker can continue moving funds even if admin pauses, (2) during connector failures, bridge operations continue when they should stop, (3) the pause role gains no control power over bridge operations.",
    "expert_notes": "This is a critical access control omission. Pausable is inherited from CoreControlled but not enforced on the most sensitive functions. The fix is trivial: add whenNotPaused to sendTokens, sendAssetsUpdate, and receiveMessage in both PortalHub and PortalOutpost. Additionally, the audit team recommends optionally restricting recovery handlers to whenPaused only (allowing admins to fix state while regular operations are stopped). InfiniFi fixed this in PR #61b0428.",
    "fix_description": "Add whenNotPaused modifier to all bridge entry points to enforce pause control across cross-chain operations.",
    "fix_code": "// PortalHub.sol\nfunction sendTokens(\n    uint256 _chainId,\n    address _token,\n    uint256 _amount,\n    address _receiver\n) external onlyRole(KEEPER_ROLE) whenNotPaused {\n    require(assetMapping[_chainId].contains(_token), \"InvalidAsset\");\n    address connectorAsset = assetMapping[_chainId].get(_token);\n    IERC20(_token).safeTransferFrom(msg.sender, address(this), _amount);\n    IConnector(connectors[_chainId]).sendTokens(_amount, connectorAsset, _receiver);\n    emit TokensSent(_chainId, _token, _amount, _receiver);\n}\n\nfunction receiveMessage(\n    uint256 _senderChainId,\n    address _connector,\n    bytes calldata _data\n) external whenNotPaused {\n    require(isConnectorValid(_senderChainId, _connector), \"InvalidConnector\");\n    (uint256 messageType, bytes memory payload) = OutlandMsgCodec.decode(_data);\n    // Process message...\n}\n\n// PortalOutpost.sol\nfunction sendTokens(\n    uint256 _chainId,\n    address _asset,\n    uint256 _amount\n) external onlyRole(KEEPER_ROLE) whenNotPaused {\n    IConnector connector = IConnector(connectors[_chainId]);\n    connector.sendTokens(_amount, asset, receiver);\n}\n\nfunction sendAssetsUpdate(\n    uint256 _destinationChain\n) external onlyRole(KEEPER_ROLE) whenNotPaused {\n    uint256 totalAssets = accounting.totalAssetsValue();\n    bytes memory data = OutlandMsgCodec.encodeAssetsUpdate(totalAssets);\n    for (uint256 i = 0; i < connectors[_destinationChain].length; i++) {\n        connectors[_destinationChain][i].sendMessage(data);\n    }\n}\n\nfunction receiveMessage(\n    address _connector,\n    bytes calldata _data\n) external whenNotPaused {\n    // Process incoming messages...\n}"
  },
  {
    "id": "gs_cantina_infinifi_003",
    "report_url": "https://cantina.xyz/portfolio/2a2026d0-0cea-4406-baac-0e1ee0ac1f66",
    "project_name": "infiniFi PR 224",
    "github_url": "https://github.com/InfiniFi-Labs/infinifi-contracts",
    "language": "solidity",
    "chain": "ethereum",
    "contest_date": "2025-11-25",
    "vulnerability_type": "missing_configuration",
    "severity": "medium",
    "difficulty_tier": 2,
    "context": "configuration",
    "is_vulnerable": true,
    "title": "LayerZero Settings Are Not Configured, Using Unintended Defaults",
    "description": "The deployment proposal does not perform any LayerZero OApp configuration (transferOwnership, setPeer, setEnforcedOptions, library setup, etc.). The ConnectorLZ relies on LayerZero defaults and unset peers, leading to routing through unintended defaults rather than explicitly configured paths. This creates operational risk and potential message loss.",
    "primary_file": {
      "name": "ConnectorLZ.sol",
      "path": "src/ConnectorLZ.sol",
      "lines": "50-80",
      "content": "contract ConnectorLZ is OApp, CoreControlled {\n    mapping(uint256 => address) public peers; // Uninitialized: all zeros\n    mapping(address => address) public ofts; // Uninitialized\n    \n    constructor(\n        address _endpoint,\n        address _delegate\n    ) OApp(_endpoint, _delegate) {\n        // MISSING CONFIGURATION:\n        // 1. No transferOwnership to multisig\n        // 2. No setPeer calls for each destination chain\n        // 3. No setEnforcedOptions for send/receive\n        // 4. No Endpoint.setSendLibrary configuration\n        // 5. No Endpoint.setReceiveLibrary configuration\n        // 6. No setConfig for compression/encoding options\n        // All these use LayerZero DEFAULTS\n    }\n    \n    function sendMessage(\n        uint256 _eidDestination,\n        bytes calldata _data\n    ) external onlyRole(KEEPER_ROLE) {\n        address peer = peers[_eidDestination]; // May be address(0)\n        if (peer == address(0)) {\n            revert(\"Peer not configured\");\n        }\n        \n        // Uses uninitialized ofts mapping\n        // May route through default send library (incorrect)\n        // Uses default confirmation requirements (may be insufficient)\n        _lzSend(\n            _eidDestination,\n            _data,\n            _enforcedOptions[_eidDestination], // Empty/default\n            MessagingFee(msg.value, address(0)),\n            payable(msg.sender)\n        );\n    }\n}"
    },
    "context_files": [
      {
        "name": "LayerZero Configuration Guide",
        "path": "reference/LayerZero_setup.md",
        "relevance": "Recommended LayerZero OApp configuration steps",
        "content": "// LayerZero OApp configuration checklist (from LayerZero docs):\n\n1. transferOwnership(multisig)\n   - Moves control from deployer to governance\n   - Without this: deployer retains all configuration power\n\n2. setPeer(eid, peer) for EACH destination chain\n   - Registers trusted remote OApp addresses\n   - Without this: peers[eid] remains address(0) or defaults\n   - Message routing cannot authenticate destination\n\n3. setEnforcedOptions(eid, options)\n   - Sets required options for send/receive on each path\n   - Specifies gas limits, execution hints, etc.\n   - Without this: uses LayerZero defaults (may be insufficient)\n\n4. Endpoint.setSendLibrary(libAddress, eid)\n   - Selects send library for each EID\n   - Options: DefaultSendLibrary, SimpleMessageLibrary, etc.\n   - Without this: uses endpoint default (unpredictable)\n\n5. Endpoint.setReceiveLibrary(libAddress, eid)\n   - Selects receive library for each EID\n   - Timeout value for stale message recovery\n   - Without this: uses endpoint default\n\n6. Endpoint.setConfig(configType, config)\n   - Sets custom configuration per path\n   - Compression, encoding, etc.\n   - Without this: uses LZ defaults\n\n7. Endpoint.setDelegate(delegateAddress)\n   - Sets address that can configure on behalf of OApp\n   - Typically the OApp itself or governance\n\nRisk: Unconfigured OApp uses DEFAULTS which may change,\nbe insufficient, or route through unexpected paths."
      },
      {
        "name": "Deployment Proposal (Partial)",
        "path": "src/deployment_proposal.sol",
        "relevance": "Shows missing configuration steps",
        "content": "// Current deployment only does:\nConnectorLZ lzConnector = new ConnectorLZ(\n    LAYERZERO_ENDPOINT,\n    address(governance)\n);\n\n// MISSING:\n// governance.transferOwnership(multisig);\n// for each chain:\n//   lzConnector.setPeer(eid[chain], peerAddress[chain]);\n//   lzConnector.setEnforcedOptions(eid[chain], encodedOptions[chain]);\n//   endpoint.setSendLibrary(sendLib, eid[chain]);\n//   endpoint.setReceiveLibrary(recvLib, eid[chain], timeout);\n//   endpoint.setConfig(CONFIG_TYPE_EXECUTOR, config);\n// \n// governance.setDelegate(lzConnector);"
      }
    ],
    "call_flow": [
      "1. ConnectorLZ deployed with endpoint and delegate only",
      "2. No transferOwnership call: deployer retains control",
      "3. No setPeer calls: peers[eid] = address(0) for all chains",
      "4. No enforced options set: uses LayerZero defaults",
      "5. No send/receive library selection: routing undefined",
      "6. Keeper calls sendMessage(eid, data)",
      "7. Message routed using unspecified send library",
      "8. Confirmation requirements unknown (uses defaults)",
      "9. Possible outcomes:",
      "   - Message routed through wrong library",
      "   - Insufficient gas limits (execution fails on destination)",
      "   - Message lost if confirmation count drops",
      "   - Routing different if LayerZero changes defaults",
      "10. Inbound message processing also uses defaults",
      "11. Receive library and timeout not configured",
      "12. Messages may time out or process with stale data",
      "13. No clear audit trail of which libraries are in use"
    ],
    "context_hint": "LayerZero requires explicit configuration for deterministic routing. An unconfigured OApp works but relies on LayerZero service defaults which: (1) may change without notice, (2) are optimized for general use, not infiniFi's specific needs, (3) may be insufficient for bridging integrity. The gap means: operators lack visibility into which libraries are in use, deployer retains unexpected control power, confirmation requirements are unknown, gas limits may be insufficient.",
    "expert_notes": "This is a configuration best-practice violation rather than a smart contract bug. The code will likely work, but with unknown characteristics. LayerZero explicitly recommends explicit configuration in their documentation. The fix requires: (1) Set all peers for each destination chain, (2) Configure send/receive libraries for each chain, (3) Set enforced options specifying gas limits and execution modes, (4) Transfer ownership to governance multisig, (5) Document which libraries and confirmations are in use. InfiniFi acknowledged this and committed to following LayerZero configuration guidance.",
    "fix_description": "Implement complete LayerZero OApp configuration per LayerZero documentation for deterministic routing and operational visibility.",
    "fix_code": "// Post-deployment configuration (off-chain or governance proposal)\n\n// 1. Transfer ownership to multisig governance\ngovernance.transferOwnership(multisigWallet);\n\n// 2. For each destination chain:\nconst chains = [\n  { eid: 30101, name: \"Arbitrum\", peer: arbitrumConnectorLZ },\n  { eid: 30110, name: \"Polygon\", peer: polygonConnectorLZ },\n  { eid: 30106, name: \"Optimism\", peer: optimismConnectorLZ },\n];\n\nfor (const chain of chains) {\n  // Set trusted peer address\n  lzConnector.setPeer(chain.eid, chain.peer);\n  \n  // Set enforced options (gas limit: 200k, execution hints for LayerZero)\n  const encodedOptions = Options.newOptions()\n    .addExecutorLzReceiveOption(200_000, 0) // 200k gas, standard execution\n    .toBytes();\n  lzConnector.setEnforcedOptions(chain.eid, encodedOptions);\n  \n  // Configure send library (e.g., SimpleMessageLibrary)\n  endpoint.setSendLibrary(SIMPLE_MESSAGE_LIBRARY, chain.eid);\n  \n  // Configure receive library with timeout\n  const timeout = 7 * 24 * 3600; // 7 days for stale recovery\n  endpoint.setReceiveLibrary(\n    SIMPLE_MESSAGE_LIBRARY,\n    chain.eid,\n    timeout\n  );\n  \n  // Set executor configuration\n  endpoint.setConfig(\n    lzConnector,\n    SIMPLE_MESSAGE_LIBRARY,\n    chain.eid,\n    ConfigType.EXECUTOR,\n    executorConfig\n  );\n}\n\n// 3. Set delegate for OApp configuration\nendpoint.setDelegate(lzConnector);\n\n// 4. Document in governance proposal which library is chosen for each chain"
  },
  {
    "id": "gs_cantina_infinifi_004",
    "report_url": "https://cantina.xyz/portfolio/2a2026d0-0cea-4406-baac-0e1ee0ac1f66",
    "project_name": "infiniFi PR 224",
    "github_url": "https://github.com/InfiniFi-Labs/infinifi-contracts",
    "language": "solidity",
    "chain": "ethereum",
    "contest_date": "2025-11-25",
    "vulnerability_type": "race_condition_accounting",
    "severity": "medium",
    "difficulty_tier": 3,
    "context": "cross_contract",
    "is_vulnerable": true,
    "title": "portalUpdate Burn Logic Sensitive to Out-of-Order Asset Updates from Cross-Chain Latency",
    "description": "The portalUpdate function in OutlandVault adjusts share balance based on reported total assets, but cross-chain message latency causes updates to arrive out-of-order relative to subsequent mint/withdraw actions. When a stale assets update arrives after newer liquidity-changing operations, it can incorrectly trigger share burns that convert previous profits into losses, misaligning share supply with actual asset position.",
    "primary_file": {
      "name": "OutlandVault.sol",
      "path": "src/OutlandVault.sol",
      "lines": "155-185",
      "content": "function portalUpdate(uint256 _totalAssetsValue) external onlyRole(PORTAL_ROLE) {\n    VaultSnapshot.Data memory snapshot = getVaultSnapshot();\n    uint256 sharesTotalBefore = snapshot.shareBalance;\n    \n    // Calculate new total shares based on remote assets + local liquidity\n    uint256 sharesTotalAfter = toShares(_totalAssetsValue) + liquidShares();\n    \n    if (sharesTotalAfter < sharesTotalBefore) {\n        // Loss scenario: burn shares\n        uint256 sharesLost = sharesTotalBefore - sharesTotalAfter;\n        uint256 sharesLiquid = liquidShares();\n        \n        if (sharesLost > sharesLiquid) {\n            uint256 sharesToBurn = sharesLost - sharesLiquid;\n            _burn(outlandFarm, sharesToBurn);\n        }\n        // VULNERABLE: No check that this _totalAssetsValue is fresh/ordered\n        // VULNERABLE: No nonce/timestamp to prevent replay of stale values\n    } else {\n        // Profit scenario: mint shares\n        uint256 sharesToMint = sharesTotalAfter - sharesTotalBefore;\n        _mint(outlandFarm, sharesToMint);\n    }\n}\n\n// PROBLEM: Can be called with stale data due to cross-chain latency\n// Example: Update at T=0 with value=100 arrives at T=T+6hrs after:\n//   - portalDeposit at T=1hr (+60 shares)\n//   - portalWithdraw at T=3hrs (-140 shares)\n//   - New state: 20 liquid, 160 shares\n// When old update(100) arrives:\n//   - sharesTotalAfter = 120 shares (stale data + current liquid)\n//   - sharesLost = 40\n//   - Incorrectly burns 40 shares, treating profit as loss"
    },
    "context_files": [
      {
        "name": "OutlandVault.sol (getMessage flow)",
        "path": "src/OutlandVault.sol",
        "relevance": "Shows how cross-chain messages trigger portalUpdate",
        "content": "// Cross-chain messaging flow (simplified):\n\n// Time T=0: Remote snapshot taken\nportalSnapshot.recordAssets(100 USDC); // value = 100\n\n// Time T=1hr: Message sent from remote portal\nsendMessage(ASSETS_UPDATE, encodeAssets(100));\n\n// Time T=1hr-3hrs: Local operations happen\nportalDeposit(+60 USDC) → shares = 160\nportalWithdraw(-140 USDC) → liquidity = 20, shares still 160\n\n// Time T=4hrs: Message arrives (delayed by network latency)\nreceiveMessage(ASSETS_UPDATE) → portalUpdate(100)\n\n// PROBLEM: portalUpdate(100) doesn't know it's stale\n// It computes based on 100 remote assets + 20 liquid = 120 total\n// But the intended total should be higher (profit not accounted for)"
      },
      {
        "name": "Race Condition Example",
        "path": "reference/race_condition_scenario.md",
        "relevance": "Detailed walkthrough of how stale updates cause incorrect burns",
        "content": "SCENARIO: Single Stale Update After Profit and Withdrawal\n\nInitial: shares=100, liquid=100, total=200\n\n1. Snapshot/report taken at T=0: totalAssets = 100 remote + 100 liquid = 200\n   Message: ASSETS_UPDATE(100) sent, arrives at T+6hrs\n\n2. Profit on L1 at T=1hr: \n   - Remote oracle reports +60 USDC profit\n   - portalUpdate(160) received\n   - sharesTotalBefore = 100\n   - sharesTotalAfter = 160 + 100 = 260\n   - sharesToMint = 160\n   - NEW STATE: shares=260, liquid=100\n\n3. Liquidity withdrawn at T=3hrs:\n   - portalWithdraw(140)\n   - 140 USDC bridged out\n   - liquidShares burned in proportion\n   - NEW STATE: shares=260, liquid=-40 (debt), bridges debt out\n\n4. STALE update arrives at T+6hrs:\n   - portalUpdate(100) <- OLD snapshot from T=0\n   - sharesTotalBefore = 260 (current shares)\n   - sharesTotalAfter = toShares(100) + liquidShares(-40)?\n   - MISMATCH: 100 is old value, 260 is current\n   - Calculation: if 100 < 260, sharesLost = 160\n   - Since sharesLost (160) > sharesLiquid, burn 160-sharesLiquid\n   - BUG: Part of the profit (160 shares) gets burned as loss\n\nRESULT: Profit turns into loss due to message ordering\n\nMULTIPLE UPDATES OUT OF ORDER:\n- Update A (T=0): value=100, arrives T+10hrs\n- Update B (T=0.5hrs): value=150, arrives T+2hrs\n- Local action at T=4hrs deposits +200\n- State now: 200 liquid + 150 pending = 350 intended\n- Update B(150) arrives: OK, increases shares\n- Update A(100) arrives later: BURNS, treating old state as new loss\n"
      }
    ],
    "call_flow": [
      "1. Remote portal takes snapshot at T=0: assets=100",
      "2. Encodes message: ASSETS_UPDATE(100)",
      "3. Sends via CCIP/LayerZero (6-hour message latency)",
      "4. Time T=1hr: Local profit detected → portalUpdate(160)",
      "5. Shares increase: 100 → 260 (profit minted)",
      "6. Time T=3hr: Large withdrawal: portalWithdraw(-140)",
      "7. Liquidity drops, shares adjusted",
      "8. Time T=6hr: STALE message ASSETS_UPDATE(100) arrives",
      "9. receiveMessage decoded: ASSETS_UPDATE, value=100",
      "10. portalUpdate(100) executed",
      "11. Calculate: sharesTotalBefore = 260 (current)",
      "12. Calculate: sharesTotalAfter = toShares(100) + liquidShares()",
      "13. Since 100 < 260: sharesLost = 160",
      "14. Burn triggered: 160 shares burned as loss",
      "15. But 160 shares were profit, not loss!",
      "16. Accounting now shows: loss where profit should be",
      "17. Later deposits/withdrawals have wrong baseline",
      "18. Share supply misaligned with actual assets"
    ],
    "context_hint": "The vulnerability exploits the asynchronous nature of cross-chain messaging. Updates include no ordering metadata (nonce, timestamp, sequence number), so a delayed message is indistinguishable from a fresh one. The function must trust that _totalAssetsValue represents the latest state, but network latency violates this assumption. The burn logic assumes messages arrive in order and represent current truth, but they may be stale relative to local state changes.",
    "expert_notes": "This is a subtle race condition between cross-chain messaging latency and local state mutations. The core issue is message ordering: updates must be applied in order, or the function must be resilient to reordering. Current options: (1) Add monotonic nonce/timestamp and reject stale updates, (2) Track last applied total and reject updates inconsistent with known liquidity changes, (3) Move to delta-based updates (mint 50 vs set to 150). The audit team recommends option 1+2. InfiniFi acknowledged this as a classic race condition and committed to batching updates every 6-8 hours with backend coordination to prevent re-ordering.",
    "fix_description": "Add monotonic ordering via nonce or timestamp and reject stale updates, or track the last applied total and validate consistency.",
    "fix_code": "// Option 1: Add nonce-based ordering\n\nuint256 private lastAppliedNonce = 0;\n\nfunction portalUpdate(\n    uint256 _totalAssetsValue,\n    uint256 _nonce\n) external onlyRole(PORTAL_ROLE) {\n    // Reject stale nonces\n    require(_nonce > lastAppliedNonce, \"StaleUpdate\");\n    lastAppliedNonce = _nonce;\n    \n    // Now safe to apply update\n    VaultSnapshot.Data memory snapshot = getVaultSnapshot();\n    uint256 sharesTotalBefore = snapshot.shareBalance;\n    uint256 sharesTotalAfter = toShares(_totalAssetsValue) + liquidShares();\n    \n    if (sharesTotalAfter < sharesTotalBefore) {\n        uint256 sharesLost = sharesTotalBefore - sharesTotalAfter;\n        uint256 farmBalance = balanceOf(outlandFarm);\n        uint256 sharesToBurn = sharesLost <= farmBalance ? sharesLost : farmBalance;\n        _burn(outlandFarm, sharesToBurn);\n    } else if (sharesTotalAfter > sharesTotalBefore) {\n        uint256 sharesToMint = sharesTotalAfter - sharesTotalBefore;\n        _mint(outlandFarm, sharesToMint);\n    }\n}\n\n// Option 2: Add timestamp and reject old timestamps\n\nuint256 private lastAppliedTimestamp = 0;\n\nfunction portalUpdate(\n    uint256 _totalAssetsValue,\n    uint256 _timestamp\n) external onlyRole(PORTAL_ROLE) {\n    // Only accept updates newer than the last one\n    require(_timestamp > lastAppliedTimestamp, \"StaleUpdate\");\n    lastAppliedTimestamp = _timestamp;\n    \n    // Apply update... (same logic as Option 1)"
  }
]